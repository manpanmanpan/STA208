{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Stucture of the cvs](https://storage.googleapis.com/kaggle-media/competitions/home-credit/home_credit.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basic analysis about the data is done by othersï¼šhttps://www.kaggle.com/codename007/home-credit-complete-eda-feature-importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['application_test.csv', 'application_train.csv', 'bureau.csv', 'bureau_balance.csv', 'credit_card_balance.csv', 'installments_payments.csv', 'POS_CASH_balance.csv', 'previous_application.csv', 'sample_submission.csv']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "PATH = \"./csv/\" \n",
    "print(os.listdir(PATH))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the data is too big (csv files are about 2.49 GB in Windows file explorer, reading in python is even larger), we need to reduce the memory usage of the data by modifying the data type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#modified from https://www.kaggle.com/gemartin/load-data-reduce-memory-usage, but not changing all the object to catagory here.\n",
    "def reduce_mem(df):\n",
    "    \"\"\"\n",
    "    modify the data type columns by columns to reduce the memory usage.\n",
    "    \"\"\"\n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtype\n",
    "        if col_type != object:\n",
    "            col_min = df[col].min()\n",
    "            col_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if col_max < np.iinfo(np.int8).max and col_min > np.iinfo(np.int8).min:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif col_max < np.iinfo(np.int16).max and col_min > np.iinfo(np.int16).min:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif col_max < np.iinfo(np.int32).max and col_min > np.iinfo(np.int32).min:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif col_max < np.iinfo(np.int64).max and col_min > np.iinfo(np.int64).min:\n",
    "                    df[col] = df[col].astype(np.int64)\n",
    "            else:\n",
    "                if col_max < np.finfo(np.float16).max and col_min > np.finfo(np.float16).min:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif col_max < np.finfo(np.float32).max and col_min > np.finfo(np.float32).min:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)\n",
    "    return df\n",
    "\n",
    "def import_csv(file):\n",
    "    df = pd.read_csv(file)\n",
    "    df = reduce_mem(df)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "reading the data. Using there file name as there variable name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#for file in os.listdir(PATH):\n",
    "#    locals()[file.split(\".\")[0]] = import_csv(PATH+file)\n",
    "#    print(file.split(\".\")[0],\":\",locals()[file.split(\".\")[0]].shape[0],\"rows and\",locals()[file.split(\".\")[0]].shape[1],\n",
    "#          \"columns, the memory usage is {:.2f} MB\".format(locals()[file.split(\".\")[0]].memory_usage().sum()/1024**2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "application_train.csv\n",
    "\n",
    "application_test.csv\n",
    "\n",
    "Combine application, using is_train variable to distinguish whether it is training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "application_train: shape (307511, 122) , the memory usage is 92.38 MB\n",
      "application_test: shape (48744, 121) , the memory usage is 14.60 MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "84"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "application_train = import_csv(PATH+\"application_train.csv\")\n",
    "print(\"application_train: shape\",application_train.shape,\n",
    "      \", the memory usage is {:.2f} MB\".format(application_train.memory_usage().sum()/1024**2))\n",
    "application_test = import_csv(PATH+\"application_test.csv\")\n",
    "print(\"application_test: shape\",application_test.shape,\n",
    "      \", the memory usage is {:.2f} MB\".format(application_test.memory_usage().sum()/1024**2))\n",
    "\n",
    "\n",
    "application_train.loc[:,\"is_train\"] = True \n",
    "application_test.loc[:,\"is_train\"] = False\n",
    "\n",
    "data = pd.concat([application_train,application_test],axis = 0)\n",
    "\n",
    "del application_train, application_test; gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#factorize the catagories variables\n",
    "cata = [i for i in data.columns if data[i].dtype == \"object\"]\n",
    "for i in cata:\n",
    "    data[i], index= pd.factorize(data[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "bureau_balance.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bureau_balance: shape (27299925, 3) , the memory usage is 338.46 MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "53"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bureau_balance = import_csv(PATH+\"bureau_balance.csv\")\n",
    "print(\"bureau_balance: shape\",bureau_balance.shape,\", the memory usage is {:.2f} MB\".format(bureau_balance.memory_usage().sum()/1024**2))\n",
    "\n",
    "#let the status to become dummies variables\n",
    "tem = pd.get_dummies(bureau_balance.STATUS, prefix='bur_bal_status')\n",
    "bureau_balance = pd.concat([bureau_balance,tem],axis = 1).drop(\"STATUS\", axis=1)\n",
    "\n",
    "#count the SK_ID_BUREAU\n",
    "bur_counts = bureau_balance[['SK_ID_BUREAU', 'MONTHS_BALANCE']].groupby('SK_ID_BUREAU').count()\n",
    "bureau_balance['buro_count'] = bureau_balance['SK_ID_BUREAU'].map(bur_counts['MONTHS_BALANCE'])\n",
    "\n",
    "#get the average of the records so that we can concat it to the main dataframe.\n",
    "avg_bur_bal = bureau_balance.groupby('SK_ID_BUREAU').mean()\n",
    "avg_bur_bal.columns = ['avg_bur_' + i for i in avg_bur_bal.columns]\n",
    "\n",
    "#release the memery space\n",
    "del bureau_balance,tem,bur_counts;gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "bureau.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bureau: shape (1716428, 17) , the memory usage is 112.95 MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bureau = import_csv(PATH+\"bureau.csv\")\n",
    "print(\"bureau: shape\",bureau.shape,\", the memory usage is {:.2f} MB\".format(bureau.memory_usage().sum()/1024**2))\n",
    "\n",
    "#let those catagories variables to become dummies.\n",
    "bur_ca_dum = pd.get_dummies(bureau.CREDIT_ACTIVE, prefix='ca_')\n",
    "bur_cc_dum = pd.get_dummies(bureau.CREDIT_CURRENCY, prefix='cc_')\n",
    "bur_ct_dum = pd.get_dummies(bureau.CREDIT_TYPE, prefix='ct_')\n",
    "bur_full = pd.concat([bureau, bur_ca_dum, bur_cc_dum, bur_ct_dum ], axis=1).drop([\"CREDIT_ACTIVE\",\"CREDIT_CURRENCY\",\"CREDIT_TYPE\"],axis = 1)\n",
    "del bur_ca_dum,bur_cc_dum,bur_ct_dum;gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine the information of bureau_balance.csv and bureau.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "126"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#merge bur_full and avg_bur_bal by 'SK_ID_BUREAU' as shown in the graph in the begining\n",
    "bur_full = bur_full.merge(right=avg_bur_bal.reset_index(), how='left', on='SK_ID_BUREAU', suffixes=('', '_bur_bal'))\n",
    "\n",
    "bur_per_cur = bur_full[['SK_ID_CURR', 'SK_ID_BUREAU']].groupby('SK_ID_CURR').count()\n",
    "bur_full['SK_ID_BUREAU'] = bur_full['SK_ID_CURR'].map(bur_per_cur['SK_ID_BUREAU'])\n",
    "\n",
    "avg_bur = bur_full.groupby('SK_ID_CURR').mean()\n",
    "\n",
    "data = data.merge(right=avg_bur.reset_index(), how='left', on='SK_ID_CURR')\n",
    "del bureau, bur_full,bur_per_cur,avg_bur;gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "POS_CASH_balance.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POS_CASH_balance: shape (10001358, 8) , the memory usage is 238.45 MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "80"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "POS_CASH_balance = import_csv(PATH+\"POS_CASH_balance.csv\")\n",
    "print(\"POS_CASH_balance: shape\",POS_CASH_balance.shape,\n",
    "      \", the memory usage is {:.2f} MB\".format(POS_CASH_balance.memory_usage().sum()/1024**2))\n",
    "\n",
    "#dummy the catagory variables.\n",
    "POS_CASH_balance = pd.concat([POS_CASH_balance, pd.get_dummies(POS_CASH_balance[\"NAME_CONTRACT_STATUS\"])],axis = 1).drop(\"NAME_CONTRACT_STATUS\",axis = 1)\n",
    "#count number of previous records\n",
    "pre_per_cur = POS_CASH_balance[[\"SK_ID_CURR\", \"SK_ID_PREV\"]].groupby(\"SK_ID_CURR\").count()\n",
    "POS_CASH_balance[\"SK_ID_PREV\"] = POS_CASH_balance[\"SK_ID_CURR\"].map(pre_per_cur[\"SK_ID_PREV\"])\n",
    "\n",
    "#get the average \n",
    "avg_pos = POS_CASH_balance.groupby(\"SK_ID_CURR\").mean()\n",
    "\n",
    "data = data.merge(right=avg_pos.reset_index(), how='left', on='SK_ID_CURR')\n",
    "del POS_CASH_balance,pre_per_cur,avg_pos;gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "previous_application.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "previous_application: shape (1670214, 37) , the memory usage is 309.01 MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "67"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "previous_application = import_csv(PATH+\"previous_application.csv\")\n",
    "print(\"previous_application: shape\",previous_application.shape,\n",
    "      \", the memory usage is {:.2f} MB\".format(previous_application.memory_usage().sum()/1024**2))\n",
    "#get all the catagories col and dummy them\n",
    "pre_cat= [ i for i in previous_application.columns if previous_application[i].dtype == 'object']\n",
    "pre_dum = pd.DataFrame()\n",
    "for i in pre_cat:\n",
    "    pre_dum = pd.concat([pre_dum, pd.get_dummies(previous_application[i], prefix=i).astype(np.uint8)], axis=1)\n",
    "previous_application = pd.concat([previous_application,pre_dum],axis = 1).drop(pre_cat,axis = 1)\n",
    "del pre_cat,pre_dum;gc.collect()\n",
    "\n",
    "#count number of previous applications\n",
    "pre_per_curr = previous_application[['SK_ID_CURR', 'SK_ID_PREV']].groupby('SK_ID_CURR').count()\n",
    "previous_application['SK_ID_PREV'] = previous_application['SK_ID_CURR'].map(pre_per_curr['SK_ID_PREV'])\n",
    "avg_pre = previous_application.groupby('SK_ID_CURR').mean()\n",
    "\n",
    "data = data.merge(right=avg_pre.reset_index(), how='left', on='SK_ID_CURR')\n",
    "del previous_application,avg_pre;gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "credit_card_balance.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "credit_card_balance: shape (3840312, 23) , the memory usage is 289.33 MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "87"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "credit_card_balance = import_csv(PATH+\"credit_card_balance.csv\")\n",
    "print(\"credit_card_balance: shape\",credit_card_balance.shape,\n",
    "      \", the memory usage is {:.2f} MB\".format(credit_card_balance.memory_usage().sum()/1024**2))\n",
    "#dummy the catagory variables.\n",
    "credit_card_balance = pd.concat([credit_card_balance,\n",
    "                                 pd.get_dummies(credit_card_balance[\"NAME_CONTRACT_STATUS\"],\n",
    "                                                prefix='cc_bal_status_')], axis=1).drop(\"NAME_CONTRACT_STATUS\",axis = 1)\n",
    "#count number of previous records\n",
    "pre_per_cur = credit_card_balance[[\"SK_ID_CURR\", \"SK_ID_PREV\"]].groupby(\"SK_ID_CURR\").count()\n",
    "credit_card_balance[\"SK_ID_PREV\"] = credit_card_balance[\"SK_ID_CURR\"].map(pre_per_cur[\"SK_ID_PREV\"])\n",
    "#get the average and avoid the variable name conflct.\n",
    "avg_cc_bal = credit_card_balance.groupby('SK_ID_CURR').mean()\n",
    "avg_cc_bal.columns = ['cc_bal_' + i for i in avg_cc_bal.columns]\n",
    "\n",
    "data = data.merge(right=avg_cc_bal.reset_index(), how='left', on='SK_ID_CURR')\n",
    "del credit_card_balance, pre_per_cur,avg_cc_bal;gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "installments_payments.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "installments_payments: shape (13605401, 8) , the memory usage is 311.40 MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "76"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "installments_payments = import_csv(PATH+\"installments_payments.csv\")\n",
    "print(\"installments_payments: shape\",installments_payments.shape,\n",
    "      \", the memory usage is {:.2f} MB\".format(installments_payments.memory_usage().sum()/1024**2))\n",
    "\n",
    "#count number of previous records\n",
    "pre_per_cur = installments_payments[[\"SK_ID_CURR\", \"SK_ID_PREV\"]].groupby(\"SK_ID_CURR\").count()\n",
    "installments_payments[\"SK_ID_PREV\"] = installments_payments[\"SK_ID_CURR\"].map(pre_per_cur[\"SK_ID_PREV\"])\n",
    "\n",
    "#get the average and avoid the variable name conflct.\n",
    "avg_ip = installments_payments.groupby('SK_ID_CURR').mean()\n",
    "avg_ip.columns = ['ip_' + i for i in avg_ip.columns]\n",
    "\n",
    "data = data.merge(right=avg_ip.reset_index(), how='left', on='SK_ID_CURR')\n",
    "del installments_payments, pre_per_cur,avg_ip;gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the final data: shape (356255, 382) , the memory usage is 744.39 MB\n"
     ]
    }
   ],
   "source": [
    "print(\"the final data: shape\",data.shape,\n",
    "      \", the memory usage is {:.2f} MB\".format(data.memory_usage().sum()/1024**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data.to_csv('data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reference:\n",
    "\n",
    "https://www.kaggle.com/gemartin/load-data-reduce-memory-usage\n",
    "\n",
    "https://www.kaggle.com/oysiyl/good-fun-with-ligthgbm/code"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
